# ğŸ¤– Bot Worker V2.0 - Chatbot Inteligente com ML AvanÃ§ado

> Sistema de chatbot inteligente que combina **Machine Learning AvanÃ§ado** (Ensemble + Topic Modeling + Ranqueamento) com **busca em 7 fontes** (Wolfram Alpha, Google, Wikipedia, arXiv, DBpedia, YouTube, DuckDuckGo), aprendizado contÃ­nuo e feedback do usuÃ¡rio.

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-3.0-green.svg)](https://flask.palletsprojects.com/)
[![scikit--learn](https://img.shields.io/badge/scikit--learn-1.5-orange.svg)](https://scikit-learn.org/)
[![MySQL](https://img.shields.io/badge/MySQL-8.0+-orange.svg)](https://www.mysql.com/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.16+-yellow.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ“‹ Ãndice

- [ğŸ¯ Sobre o Projeto](#-sobre-o-projeto)
- [âœ¨ Funcionalidades](#-funcionalidades)
- [ğŸ—ï¸ Arquitetura](#ï¸-arquitetura)
- [ğŸ§  Machine Learning](#-machine-learning)
- [ğŸ” Fontes de Busca](#-fontes-de-busca)
- [ğŸ› ï¸ Tecnologias](#ï¸-tecnologias)
- [ğŸ“¦ InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [âš™ï¸ ConfiguraÃ§Ã£o](#ï¸-configuraÃ§Ã£o)
- [ğŸš€ Deploy](#-deploy)
- [ğŸ“¡ API](#-api)
- [ğŸ”„ Retreinamento](#-retreinamento)
- [ğŸ“Š MÃ©tricas](#-mÃ©tricas)
- [ğŸ—ºï¸ Roadmap](#ï¸-roadmap)

---

## ğŸ¯ Sobre o Projeto

O **Bot Worker V2.0** Ã© um chatbot de prÃ³xima geraÃ§Ã£o que **nÃ£o depende de LLMs caras**. Em vez disso:

### ğŸš€ **Como Funciona**

1. **Analisa a pergunta** usando NLP avanÃ§ado (spaCy + anÃ¡lise semÃ¢ntica)
2. **ML Ensemble prevÃª intenÃ§Ã£o** (Naive Bayes + Random Forest + Gradient Boosting + LSTM opcional)
3. **Ranqueia fontes inteligentemente** (ML + histÃ³rico de sucessos)
4. **Busca em paralelo** nas 7 melhores fontes (Wolfram, Google, Wikipedia, arXiv, DBpedia, YouTube, DuckDuckGo)
5. **Combina respostas** usando TF-IDF e similaridade semÃ¢ntica
6. **Aprende continuamente** com feedback e correÃ§Ãµes do usuÃ¡rio
7. **Armazena tudo** no MySQL com logs detalhados

### ğŸ¯ **Diferenciais**

âœ… **100% Gratuito** - Sem dependÃªncia de APIs pagas (LLMs)  
âœ… **Ensemble ML** - 4 modelos votando para maior precisÃ£o  
âœ… **7 Fontes** - Combina mÃºltiplas fontes automaticamente  
âœ… **Ranqueamento Inteligente** - ML aprende quais fontes funcionam melhor  
âœ… **Topic Modeling** - LDA descobre padrÃµes e tendÃªncias  
âœ… **Aprendizado ContÃ­nuo** - Melhora com uso e feedback  
âœ… **Modo ProduÃ§Ã£o** - Otimizado para rodar com < 512 MB RAM  

---

## âœ¨ Funcionalidades

### ğŸ” **Busca Inteligente**
- âœ… **7 fontes simultÃ¢neas** (Wolfram, Google, DuckDuckGo, Wikipedia, arXiv, DBpedia, YouTube)
- âœ… **Busca paralela** com early stopping (para quando encontra resposta boa)
- âœ… **Ranqueamento ML** (combina modelo ML + estatÃ­sticas histÃ³ricas)
- âœ… **CombinaÃ§Ã£o inteligente** (mescla melhores respostas de mÃºltiplas fontes)
- âœ… **Cache semÃ¢ntico** (respostas < 0.1s para perguntas similares)

### ğŸ§  **Machine Learning AvanÃ§ado**

#### **1. Ensemble de Classificadores (IntenÃ§Ã£o)**
- âœ… **Naive Bayes** - RÃ¡pido, baseline sÃ³lido
- âœ… **Random Forest** - Robusto a overfitting
- âœ… **Gradient Boosting** - Alta performance
- âœ… **LSTM** (opcional) - Deep Learning para contexto longo
- âœ… **Voting ponderado** por confianÃ§a

#### **2. Ranqueador Inteligente de Fontes**
- âœ… **Random Forest** treina com histÃ³rico de sucessos
- âœ… **Features:** tipo de pergunta + entidades + contexto temporal
- âœ… **Score hÃ­brido:** 70% ML + 30% estatÃ­sticas histÃ³ricas
- âœ… **Top-K selection:** Seleciona 5 melhores fontes

#### **3. Topic Modeling (LDA)**
- âœ… **20 tÃ³picos** descobertos automaticamente
- âœ… **Agrupa perguntas similares** para anÃ¡lise de tendÃªncias
- âœ… **Melhora ranqueamento** (fontes boas em tÃ³picos especÃ­ficos)

#### **4. Aprendizado ContÃ­nuo**
- âœ… **Cache semÃ¢ntico** (TF-IDF + Cosine Similarity > 0.85)
- âœ… **PadrÃµes aprendidos** de respostas com qualidade > 0.7
- âœ… **EstatÃ­sticas detalhadas** por fonte (taxa de sucesso, tempo mÃ©dio, qualidade)
- âœ… **Retreinamento periÃ³dico** (a cada 100 conversas ou sob demanda)

### ğŸ’¾ **PersistÃªncia e HistÃ³rico**
- âœ… **Todas as conversas** salvas no MySQL
- âœ… **HistÃ³rico paginado** com busca
- âœ… **Logs detalhados** no campo `metadata` (JSON)
- âœ… **EstatÃ­sticas** por usuÃ¡rio e global
- âœ… **Feedback explÃ­cito** (positivo/negativo/correÃ§Ãµes)

### ğŸ‘¥ **Sistema de UsuÃ¡rios**
- âœ… **AutenticaÃ§Ã£o JWT**
- âœ… **Cadastro e login**
- âœ… **HistÃ³rico individual**
- âœ… **Controle de ownership** (usuÃ¡rio sÃ³ vÃª/edita suas conversas)

### ğŸš€ **Modo ProduÃ§Ã£o Otimizado**
- âœ… **Feature flags** (`PRODUCAO=true`)
- âœ… **TensorFlow desabilitado** em produÃ§Ã£o (economia de RAM)
- âœ… **spaCy ultra-leve** (apenas tokenizaÃ§Ã£o + NER)
- âœ… **Lazy loading** (modelos carregados sob demanda)
- âœ… **< 512 MB RAM** (compatÃ­vel com Render/Railway free tier)

---

## ğŸ—ï¸ Arquitetura

### **PadrÃ£o: Model â†’ Repository â†’ Worker â†’ Controller**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FRONTEND (Separado)                â”‚
â”‚           Next.js / React / PWA                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ REST API (32 endpoints)
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Flask API Controllers                 â”‚
â”‚  â”œâ”€ bot_controller.py (29 endpoints)            â”‚
â”‚  â””â”€ user_controller.py (3 endpoints)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Business Logic (Workers)            â”‚
â”‚  â”œâ”€ BotWorkerV2 (Singleton)                     â”‚
â”‚  â”‚   â”œâ”€ Sistema ML AvanÃ§ado                     â”‚
â”‚  â”‚   â”œâ”€ Buscador Unificado (7 fontes)           â”‚
â”‚  â”‚   â””â”€ Sistema de Feedback                     â”‚
â”‚  â””â”€ UserWorker (Auth JWT + bcrypt)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Machine Learning Layer                  â”‚
â”‚  â”œâ”€ Ensemble (NB + RF + GB + LSTM*)             â”‚
â”‚  â”œâ”€ Ranqueador de Fontes (Random Forest)        â”‚
â”‚  â”œâ”€ Topic Model (LDA - 20 tÃ³picos)              â”‚
â”‚  â””â”€ Cache SemÃ¢ntico (TF-IDF + Cosine)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Data Access (Repositories)         â”‚
â”‚  â”œâ”€ BotRepository (16 mÃ©todos CRUD)             â”‚
â”‚  â””â”€ UserRepository (3 mÃ©todos)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           MySQL Database (Railway)              â”‚
â”‚  â”œâ”€ usuarios (id, nome, email, senha_hash)      â”‚
â”‚  â””â”€ bot_conversations (id, user_id, pergunta,   â”‚
â”‚      resposta, fonte, tempo, status,            â”‚
â”‚      metadata JSON, created_at)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Machine Learning

### **Ensemble de Modelos (IntenÃ§Ã£o)**

Combina 4 algoritmos para detectar intenÃ§Ã£o com alta precisÃ£o:

| Modelo | Tipo | Vantagem | AcurÃ¡cia |
|--------|------|----------|----------|
| **Naive Bayes** | ProbabilÃ­stico | RÃ¡pido, baseline sÃ³lido | ~85% |
| **Random Forest** | Ensemble | Robusto, features importantes | ~92% |
| **Gradient Boosting** | Boosting | Alta performance | ~94% |
| **LSTM*** | Deep Learning | Contexto longo, sequÃªncias | ~89% |

> *LSTM Ã© **opcional** e desabilitado em produÃ§Ã£o (`PRODUCAO=true`) para economizar RAM.

**Voting Ponderado:**
```python
# Cada modelo vota com peso = confianÃ§a
votos = {
    "conhecimento": 0.95 (NB) + 0.88 (RF) + 0.92 (GB) = 2.75,
    "saudacao": 0.05 (NB) + 0.12 (RF) + 0.08 (GB) = 0.25
}

# Vencedor: "conhecimento" (confianÃ§a = 2.75 / 3 = 0.92)
```

### **Ranqueador Inteligente de Fontes**

Treina **Random Forest** com histÃ³rico de conversas:

**Features extraÃ­das:**
- Tipo de pergunta (qual, como, por que, etc)
- Entidades presentes (PERSON, LOC, ORG, DATE)
- POS tags (substantivos, verbos, adjetivos)
- Contexto temporal (atual vs histÃ³rico)

**Score hÃ­brido:**
```python
score_final = (score_ml * 0.7) + (taxa_sucesso_historica * 0.3)
```

**Output:**
```python
[
    ("wikipedia", 0.89),  # Melhor fonte
    ("google", 0.72),
    ("wolfram", 0.45),
    ...
]
```

### **Topic Modeling (LDA)**

Descobre **20 tÃ³picos** automaticamente:

```python
TÃ³pico 0: ["brasil", "capital", "paÃ­s", "cidade", "estado"]
TÃ³pico 1: ["cÃ¡lculo", "nÃºmero", "matemÃ¡tica", "resultado"]
TÃ³pico 5: ["histÃ³ria", "guerra", "ano", "sÃ©culo", "evento"]
...
```

**Uso:**
- Agrupa perguntas similares
- Melhora ranqueamento (ex: Wolfram Ã© Ã³timo no tÃ³pico 1 - cÃ¡lculo)
- AnÃ¡lise de tendÃªncias

---

## ğŸ” Fontes de Busca

### **7 Fontes Integradas**

| Fonte | Especialidade | API Key | Status |
|-------|---------------|---------|--------|
| **Wolfram Alpha** | CÃ¡lculos, conversÃµes, fatos cientÃ­ficos | âœ… NecessÃ¡ria | âœ… |
| **Google Custom Search** | InformaÃ§Ã£o geral, notÃ­cias, recente | âœ… NecessÃ¡ria | âœ… |
| **DuckDuckGo** | Busca alternativa, privada, sem tracking | âŒ NÃ£o | âœ… |
| **Wikipedia** | Conhecimento enciclopÃ©dico estruturado | âŒ NÃ£o | âœ… |
| **arXiv** | Papers cientÃ­ficos, pesquisa acadÃªmica | âŒ NÃ£o | âœ… |
| **DBpedia** | Dados estruturados (triplas RDF) | âŒ NÃ£o | âœ… |
| **YouTube** | TranscriÃ§Ãµes de vÃ­deos educacionais | âŒ NÃ£o | âœ… |

### **EstratÃ©gia de Busca**

1. **AnÃ¡lise AvanÃ§ada** â†’ Extrai entidades, tipo, complexidade
2. **Ranqueamento ML** â†’ Seleciona top 5 fontes
3. **Busca Paralela** â†’ ThreadPoolExecutor (max 5 workers)
4. **Early Stopping** â†’ Para quando encontra 2 respostas boas (>100 chars)
5. **CombinaÃ§Ã£o Inteligente** â†’ TF-IDF + remoÃ§Ã£o de duplicatas

---

## ğŸ› ï¸ Tecnologias

### **Backend**
- **Flask 3.0** - Framework web minimalista
- **Gunicorn** - WSGI server para produÃ§Ã£o
- **Python 3.11** - Linguagem base

### **Machine Learning**
- **scikit-learn 1.5** - Ensemble (NB, RF, GB), TF-IDF, LDA
- **TensorFlow 2.16*** - Deep Learning (LSTM)
- **NumPy 1.26** - OperaÃ§Ãµes numÃ©ricas
- **spaCy 3.7** - NLP (tokenizaÃ§Ã£o, NER, POS)

> *TensorFlow Ã© **opcional** e desabilitado em produÃ§Ã£o.

### **APIs Externas**
- **Wolfram Alpha API** - CÃ¡lculos cientÃ­ficos
- **Google Custom Search API** - Busca web
- **DuckDuckGo Instant Answer** - Busca sem tracking
- **Wikipedia API** - Conhecimento enciclopÃ©dico
- **arXiv API** - Papers cientÃ­ficos
- **DBpedia SPARQL** - Dados estruturados
- **YouTube Transcript API** - TranscriÃ§Ãµes de vÃ­deos

### **Banco de Dados**
- **MySQL 8.0+** - Armazenamento persistente
- **Connection Pool** - 5 conexÃµes simultÃ¢neas

### **UtilitÃ¡rios**
- **langdetect** - DetecÃ§Ã£o automÃ¡tica de idioma
- **deep-translator** - TraduÃ§Ã£o (Google Translate)
- **cachetools** - Cache em memÃ³ria (TTL)
- **bcrypt** - Hash de senhas
- **PyJWT** - Tokens de autenticaÃ§Ã£o

---

## ğŸ“¦ InstalaÃ§Ã£o

### 1ï¸âƒ£ **Clone o repositÃ³rio**

```bash
git clone https://github.com/garotinhosDePrograma/bot-prototype.git
cd bot-prototype
```

### 2ï¸âƒ£ **Crie um ambiente virtual**

```bash
python -m venv venv

# Linux/Mac
source venv/bin/activate

# Windows
venv\Scripts\activate
```

### 3ï¸âƒ£ **Instale as dependÃªncias**

```bash
# IMPORTANTE: Use --break-system-packages se necessÃ¡rio
pip install -r requirements.txt

# Baixe o modelo spaCy
python -m spacy download pt_core_news_sm
```

### 4ï¸âƒ£ **Configure as variÃ¡veis de ambiente**

```bash
cp .env.example .env
```

Edite `.env`:

```env
# Modo (false = dev, true = produÃ§Ã£o)
PRODUCAO=false

# Banco de dados (Railway ou local)
CONN_URL=mysql://usuario:senha@host:porta/database

# APIs externas (opcional mas recomendado)
WOLFRAM_APP_ID=seu_app_id_wolfram
GOOGLE_CX=seu_custom_search_engine_id
GOOGLE_API_KEY=sua_google_api_key

# JWT (para autenticaÃ§Ã£o)
SECRET_KEY=sua_chave_secreta_aqui
```

### 5ï¸âƒ£ **Crie as tabelas no banco**

```bash
# Tabela de usuÃ¡rios
python script.py

# Tabela de conversas do bot
python migrations/create_bot_conversations_table.py
```

### 6ï¸âƒ£ **(Opcional) Treine os modelos ML**

Se vocÃª quiser treinar do zero (caso contrÃ¡rio, use os modelos prÃ©-treinados):

```bash
python
>>> from bot.bot_worker_v2 import get_bot_worker
>>> bot = get_bot_worker()
>>> bot.sistema_ml.retreinar_tudo()
```

> âš ï¸ **Requer pelo menos 100 conversas no banco para treinar.**

### 7ï¸âƒ£ **Inicie o servidor**

```bash
python app.py
```

A API estarÃ¡ disponÃ­vel em `http://localhost:5000`

---

## âš™ï¸ ConfiguraÃ§Ã£o

### **Obter API Keys (Opcional mas Recomendado)**

#### **Wolfram Alpha**
1. Acesse https://products.wolframalpha.com/api/
2. Crie uma conta gratuita
3. Obtenha seu **App ID** (2.000 queries/mÃªs grÃ¡tis)

#### **Google Custom Search**
1. Acesse https://programmablesearchengine.google.com/
2. Crie um novo search engine
3. Anote o **Search Engine ID (CX)**
4. Ative a API em https://console.cloud.google.com/
5. Crie uma **API Key** (100 queries/dia grÃ¡tis)

> **Nota:** DuckDuckGo, Wikipedia, arXiv, DBpedia e YouTube **nÃ£o requerem API keys**.

### **Configurar Banco de Dados (Railway)**

1. Acesse https://railway.app/
2. Crie um novo projeto MySQL
3. Copie a `CONN_URL` fornecida
4. Cole no arquivo `.env`

### **Modo ProduÃ§Ã£o**

Para ativar otimizaÃ§Ãµes de produÃ§Ã£o:

```bash
export PRODUCAO=true
```

**OtimizaÃ§Ãµes aplicadas:**
- âœ… TensorFlow desabilitado (economia de ~400 MB RAM)
- âœ… spaCy ultra-leve (apenas tokenizaÃ§Ã£o + NER)
- âœ… TF-IDF reduzido (500 features vs 1000 em dev)
- âœ… Cache menor (200 vs 200 em dev)
- âœ… Menos workers (3 vs 4 em dev)

---

## ğŸš€ Deploy

### **Render (Recomendado - Free Tier)**

#### **1. PreparaÃ§Ã£o**

```bash
# Certifique-se que modelos estÃ£o no Git
ls -lh bot/ml/modelos_avancados/modelos_ensemble.pkl

# Se arquivo > 100MB, use Git LFS
git lfs install
git lfs track "bot/ml/modelos_avancados/*.pkl"
git add .gitattributes
git commit -m "feat: adiciona modelos ML (LFS)"
git push
```

#### **2. Criar Web Service**

1. Acesse https://dashboard.render.com/
2. **New** â†’ **Web Service**
3. Conecte seu repositÃ³rio GitHub
4. Configure:

```yaml
Name: bot-worker-api
Environment: Python 3
Build Command: pip install -r requirements.txt && python -m spacy download pt_core_news_sm
Start Command: gunicorn app:app
```

#### **3. VariÃ¡veis de Ambiente**

```
PRODUCAO=true
CONN_URL=mysql://usuario:senha@host:porta/database
WOLFRAM_APP_ID=seu_app_id
GOOGLE_CX=seu_cx
GOOGLE_API_KEY=sua_key
```

#### **4. Deploy**

Clique em **Create Web Service**. O deploy levarÃ¡ ~5 minutos.

#### **5. Verificar**

```bash
# Health check
curl https://seu-app.onrender.com/api/bot/health

# Teste de pergunta
curl -X POST https://seu-app.onrender.com/api/bot/question \
  -H "Content-Type: application/json" \
  -d '{"pergunta":"Qual a capital da FranÃ§a?","user_id":1}'
```

### **Railway (Alternativa)**

```bash
# Instale Railway CLI
npm install -g @railway/cli

# Login
railway login

# Inicialize
railway init

# Deploy
railway up
```

### **Limites Free Tier**

| Plataforma | RAM | CPU | Uptime | Cold Start |
|-----------|-----|-----|--------|------------|
| **Render** | 512 MB | 0.1 | 750h/mÃªs | ~30s apÃ³s 15min inativo |
| **Railway** | 500 MB | Compartilhado | $5 crÃ©dito/mÃªs | Sem hibernaÃ§Ã£o |

> **RecomendaÃ§Ã£o:** Render para produÃ§Ã£o, Railway para testes.

---

## ğŸ“¡ API

### **Base URL**
```
http://localhost:5000      # Dev
https://seu-app.onrender.com  # ProduÃ§Ã£o
```

### **AutenticaÃ§Ã£o**

Endpoints de usuÃ¡rio requerem JWT:

```bash
# 1. Login
curl -X POST http://localhost:5000/api/login \
  -H "Content-Type: application/json" \
  -d '{"email":"usuario@email.com","senha":"123456"}'

# Response: {"token": "eyJ...", "user": {...}}

# 2. Use o token
curl -X GET http://localhost:5000/api/all \
  -H "Authorization: Bearer eyJ..."
```

### **Endpoints Principais**

#### **ğŸ¤– Bot Endpoints**

##### **Fazer uma pergunta**
```bash
POST /api/bot/question
```

**Request:**
```json
{
  "pergunta": "Como funciona a fotossÃ­ntese?",
  "user_id": 1  // opcional
}
```

**Response:**
```json
{
  "status": "success",
  "query": "Como funciona a fotossÃ­ntese?",
  "response": "Basicamente, fotossÃ­ntese Ã© o processo...",
  "source": "google+wikipedia",
  "processing_time": 1.234,
  "user_id": 1,
  "version": "2.0",
  "logs_processo": [...]
}
```

##### **Buscar histÃ³rico**
```bash
GET /api/bot/history?user_id=1&limit=20&offset=0
```

##### **EstatÃ­sticas**
```bash
GET /api/bot/stats?user_id=1
```

**Response:**
```json
{
  "status": "success",
  "statistics": {
    "total_perguntas": 150,
    "tempo_medio": 1.23,
    "cache_hits": 45,
    "taxa_cache": 30.0,
    "sucessos": 145,
    "erros": 5,
    "taxa_sucesso": 96.7,
    "fontes_mais_usadas": [
      {"fonte": "google", "count": 60},
      {"fonte": "wikipedia", "count": 40}
    ]
  }
}
```

##### **Feedback**
```bash
POST /api/bot/feedback
```

**Request:**
```json
{
  "conversation_id": 123,
  "tipo": "positivo",  // "positivo", "negativo", "neutro"
  "detalhes": "Resposta muito Ãºtil!"
}
```

##### **CorreÃ§Ã£o**
```bash
POST /api/bot/feedback/correcao
```

**Request:**
```json
{
  "conversation_id": 123,
  "resposta_correta": "A resposta correta Ã©..."
}
```

##### **Health Check AvanÃ§ado**
```bash
GET /api/bot/health
```

**Response:**
```json
{
  "status": "online",
  "modo_producao": true,
  "modelos_carregados": {
    "ensemble_nb": true,
    "ensemble_rf": true,
    "ensemble_gb": true,
    "lstm": false,
    "ranqueador": true,
    "lda": true
  },
  "cache_size": 200,
  "deep_learning": false
}
```

#### **ğŸ‘¥ User Endpoints**

##### **Registrar**
```bash
POST /api/register
```

```json
{
  "nome": "JoÃ£o Silva",
  "email": "joao@email.com",
  "senha": "senha123"
}
```

##### **Login**
```bash
POST /api/login
```

```json
{
  "email": "joao@email.com",
  "senha": "senha123"
}
```

#### **ğŸ”§ Admin Endpoints (âš ï¸ Adicionar autenticaÃ§Ã£o)**

##### **Retreinar todos modelos**
```bash
POST /api/bot/admin/retrain-all
```

##### **Recarregar modelos (sem restart)**
```bash
POST /api/bot/admin/reload-models
```

##### **Ver tÃ³picos LDA**
```bash
GET /api/bot/admin/topics
```

##### **EstatÃ­sticas avanÃ§adas de fontes**
```bash
GET /api/bot/admin/stats/fontes-avancadas
```

##### **Ranquear fontes para pergunta**
```bash
POST /api/bot/admin/fontes/ranking
```

```json
{
  "pergunta": "Qual a capital da FranÃ§a?"
}
```

**Response:**
```json
{
  "status": "success",
  "pergunta": "Qual a capital da FranÃ§a?",
  "ranking": [
    {"fonte": "wikipedia", "score": 0.89},
    {"fonte": "google", "score": 0.72},
    {"fonte": "wolfram", "score": 0.45}
  ]
}
```

---

## ğŸ”„ Retreinamento

### **Quando Retreinar**

- âœ… A cada **100+ novas conversas**
- âœ… **Semanalmente** se trÃ¡fego alto
- âœ… ApÃ³s **mudanÃ§as significativas** no conteÃºdo
- âœ… Quando **taxa de sucesso cair** abaixo de 85%

### **Processo (Google Colab)**

#### **1. Preparar ambiente**

```python
# No Google Colab
!git clone https://github.com/garotinhosDePrograma/bot-prototype.git
%cd bot-prototype

!pip install -r requirements.txt
!python -m spacy download pt_core_news_sm
```

#### **2. Configurar**

```python
import os

# Banco de PRODUÃ‡ÃƒO (lÃª dados reais)
os.environ['CONN_URL'] = 'mysql://usuario:senha@host:porta/database'

# Modo DEV no Colab (habilita TensorFlow)
os.environ['PRODUCAO'] = 'false'
```

#### **3. Treinar**

```python
from bot.bot_worker_v2 import get_bot_worker

bot = get_bot_worker()

# Treina TUDO (ensemble + ranqueador + LDA)
bot.sistema_ml.retreinar_tudo()

# Ou treinar individualmente:
# bot.sistema_ml.treinar_detector_intencao_ensemble()
# bot.sistema_ml.treinar_ranqueador_fontes()
# bot.sistema_ml.treinar_topic_model()
```

#### **4. Download modelos**

```python
from google.colab import files

files.download("bot/ml/modelos_avancados/modelos_ensemble.pkl")
```

#### **5. Deploy**

```bash
# Localmente apÃ³s download
cp ~/Downloads/modelos_ensemble.pkl bot/ml/modelos_avancados/

git add bot/ml/modelos_avancados/
git commit -m "feat: retreinamento com 200+ novas conversas"
git push

# Render farÃ¡ redeploy automÃ¡tico
```

#### **6. Recarregar (opcional)**

```bash
# Sem restart do servidor
curl -X POST https://seu-app.onrender.com/api/bot/admin/reload-models
```

### **Monitoramento**

```bash
# Verificar performance
curl https://seu-app.onrender.com/api/bot/admin/model-performance
```

---

## ğŸ“Š MÃ©tricas

### **Startup**
- âœ… **Build time:** < 5 min
- âœ… **Cold start:** < 30s (Render free tier)
- âœ… **Warm start:** < 1s
- âœ… **Health check:** 200 OK

### **Funcionalidade**
- âœ… **Ensemble ML:** 4 modelos ativos
- âœ… **Ranqueamento:** Funcionando
- âœ… **Topic Modeling:** 20 tÃ³picos
- âœ… **Cache semÃ¢ntico:** Ativo
- âœ… **Feedback:** Registrando

### **Performance**
- âœ… **Tempo de resposta:** < 3s (mÃ©dia)
- âœ… **Taxa de cache:** > 20%
- âœ… **Taxa de sucesso:** > 90%
- âœ… **Uptime:** 99.9% (exceto cold starts)

### **Recursos**
- âœ… **RAM (dev):** ~800 MB
- âœ… **RAM (prod):** ~350 MB
- âœ… **CPU:** Baixo (picos apenas durante busca)
- âœ… **Disco:** ~150 MB (com modelos)

---

## ğŸ—ºï¸ Roadmap

### âœ… **ConcluÃ­do (V2.0)**
- [x] Ensemble ML (NB + RF + GB + LSTM)
- [x] Ranqueamento inteligente de fontes
- [x] Topic Modeling (LDA)
- [x] 7 fontes de busca integradas
- [x] Sistema de feedback e correÃ§Ãµes
- [x] Aprendizado contÃ­nuo
- [x] Modo produÃ§Ã£o otimizado (< 512 MB RAM)
- [x] API REST completa (32 endpoints)
- [x] HistÃ³rico detalhado com paginaÃ§Ã£o
- [x] EstatÃ­sticas avanÃ§adas
- [x] Cache semÃ¢ntico

### ğŸ”œ **PrÃ³ximos Passos (V2.1)**

#### **Curto Prazo (1-2 semanas)**
- [ ] AutenticaÃ§Ã£o nos endpoints `/admin/*`
- [ ] Rate limiting (100 req/min por IP)
- [ ] Dashboard de mÃ©tricas (Grafana)
- [ ] Logs estruturados (structlog)
- [ ] Health checks mais detalhados

#### **MÃ©dio Prazo (1 mÃªs)**
- [ ] GitHub Actions CI/CD
- [ ] Testes automatizados (pytest, 80%+ coverage)
- [ ] Cache distribuÃ­do (Redis)
- [ ] Filas assÃ­ncronas (Celery)
- [ ] Webhooks para notificaÃ§Ãµes

#### **Longo Prazo (3+ meses)**
- [ ] RAG (Retrieval Augmented Generation)
- [ ] Fine-tuning de modelos open-source (LLaMA, Mistral)
- [ ] Multi-tenancy
- [ ] API pÃºblica com API keys
- [ ] SDK em Python/JavaScript
- [ ] Embeddings prÃ³prios (sentence-transformers)

### ğŸ¯ **Features Experimentais**
- [ ] IntegraÃ§Ã£o com Stack Overflow API
- [ ] IntegraÃ§Ã£o com Reddit API
- [ ] Suporte a imagens (OCR + Image Search)
- [ ] Suporte a Ã¡udio (Speech-to-Text)
- [ ] ConversaÃ§Ã£o multi-turno (contexto entre perguntas)
- [ ] PersonalizaÃ§Ã£o por usuÃ¡rio

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido por **Luiz Fagner**

- GitHub: [@WirkLichKeit1](https://github.com/WirkLichKeit1)
- Projeto: [Bot Prototype](https://github.com/garotinhosDePrograma/bot-prototype)

---

## ğŸ“ Suporte

### **Problemas Comuns**

#### **"No module named 'tensorflow'"**
âœ… **NORMAL** - TensorFlow desabilitado em produÃ§Ã£o (`PRODUCAO=true`)

#### **"File not found: modelos_ensemble.pkl"**
```bash
# Verifique se modelos estÃ£o no Git
ls -lh bot/ml/modelos_avancados/

# Se nÃ£o, adicione
git add bot/ml/modelos_avancados/
git push
```

#### **Cold start lento**
âœ… **NORMAL** no Render free - Primeira request apÃ³s 15min inatividade demora ~30s

### **Contato**

Encontrou um bug? Tem uma sugestÃ£o?

- ğŸ› Abra uma [issue](https://github.com/garotinhosDePrograma/bot-prototype/issues)
- ğŸ”§ Envie um [pull request](https://github.com/garotinhosDePrograma/bot-prototype/pulls)

---

## ğŸ™ Agradecimentos

- **spaCy** - NLP toolkit incrÃ­vel
- **scikit-learn** - ML clÃ¡ssico robusto
- **TensorFlow** - Deep Learning
- **Flask** - Framework web minimalista
- **Railway/Render** - Hospedagem gratuita
- **Wolfram Alpha** - API de conhecimento
- **Google** - Custom Search API

---
## ğŸ“š DocumentaÃ§Ã£o adicional

- [ğŸ“Š AnÃ¡lise TÃ©cnica Completa](ANALISE_PROJETO.md)

---

**â­ Se este projeto foi Ãºtil, deixe uma estrela no GitHub!**

---

**Bot Worker V2.0** - Chatbot Inteligente sem LLMs
